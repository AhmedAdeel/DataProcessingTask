{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c68bfc-6e35-4bfb-b83f-fb14b762e59e",
   "metadata": {},
   "source": [
    "### 1 - Import Libraries and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3cbeec-16f0-4e6a-a6ab-f23a0937e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01365365-ea66-4908-88f5-1a7d6dfb03a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. Load Dataset\n",
    "df = pd.read_csv(\"Company.csv\")\n",
    "# 3. Basic Structure\n",
    "print(\"ðŸ“Š Dataset Shape:\", df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a996cb-9b59-4f80-8c58-c649622cd9f9",
   "metadata": {},
   "source": [
    "### 2 - Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d5aec-ae99-4ebe-b173-0f2492f8f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Preview Data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3555a90a-ee8e-430a-abcd-7ab12c374719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5. Summary Statistics (Including Strings)\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fae9c1b-73e5-4916-8ef4-2f4d3f509f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Missing Values\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "print(\"Columns with Missing Values:\\n\", missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e772cb-6ffe-4a8a-a43a-36abac0c73f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Visualize Missing Data\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap=\"YlOrRd\")\n",
    "plt.title(\"Missing Values Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03922617-b51a-4c8f-bea5-511a8fa77bc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 9. Top Company Names (possible duplicates)\n",
    "print(\"Top Repeated Company Names:\\n\", df[\"CompanyName\"].value_counts().head(10))\n",
    "\n",
    "# 10. Unique Value Counts Per Column (Optional deeper check)\n",
    "unique_counts = df.nunique().sort_values(ascending=True)\n",
    "print(\"Unique Values per Column:\\n\", unique_counts)\n",
    "\n",
    "# 11. Column-specific Inspection (Optional: e.g., PostTown)\n",
    "print(df[\"RegAddress.PostTown\"].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9134a30-bf0b-43a6-8fb2-c13573b70d43",
   "metadata": {},
   "source": [
    "### 3 - Cleansing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe77f2a-f0bd-4f05-bfda-648a35823977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Drop columns where all values are NaN\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# 2. Strip whitespace from column names (optional but helpful)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# 3. Trim whitespace in all string/object columns\n",
    "str_cols = df.select_dtypes(include=['object']).columns\n",
    "df[str_cols] = df[str_cols].apply(lambda x: x.str.strip())\n",
    "\n",
    "cols_to_int = [\n",
    "    'Accounts.AccountRefDay',\n",
    "    'Accounts.AccountRefMonth',\n",
    "    'Mortgages.NumMortCharges',\n",
    "    'Mortgages.NumMortOutstanding',\n",
    "    'Mortgages.NumMortPartSatisfied',\n",
    "    'Mortgages.NumMortSatisfied',\n",
    "    'LimitedPartnerships.NumGenPartners',\n",
    "    'LimitedPartnerships.NumLimPartners'\n",
    "]\n",
    "\n",
    "for col in cols_to_int:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')\n",
    "        \n",
    "# 4. Standardize casing (e.g., uppercase company name)\n",
    "if 'CompanyName' in df.columns:\n",
    "    df['CompanyName'] = df['CompanyName'].str.upper()\n",
    "df = df.rename(columns={\n",
    "    'Returns.NextDueDate': 'ReturnsNextDueDate',\n",
    "    'Returns.LastMadeUpDate': 'ReturnsLastMadeUpDate'\n",
    "})\n",
    "# 5. Convert common date fields to datetime (ignore errors)\n",
    "date_columns = [col for col in df.columns if 'Date' in col]\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], format='%d/%m/%Y', errors='coerce')\n",
    "# 6. Show result\n",
    "print(\"Cleansing completed. New shape:\", df.shape)\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88360f23-83f9-4b71-b5d5-3804d136e322",
   "metadata": {},
   "source": [
    "### 4 - Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e82b61-46f7-498a-8d8c-c5f23b0807db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Group by CompanyNumber and merge fields\n",
    "def merge_group(group):\n",
    "    # Take the first non-null value from each column\n",
    "    return group.ffill().bfill().iloc[0]\n",
    "\n",
    "# Only apply if CompanyNumber column exists\n",
    "if 'CompanyNumber' in df.columns:\n",
    "    # Create merged DataFrame by group\n",
    "    df_unique = df.groupby('CompanyNumber', as_index=False).apply(merge_group)\n",
    "\n",
    "    # Reset index after groupby\n",
    "    df_unique.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Deduplication done. Reduced from {df.shape[0]} to {df_unique.shape[0]} rows.\")\n",
    "else:\n",
    "    print(\"CompanyNumber column not found for deduplication.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c132ffe-a6d0-4d07-ad01-7d81f2ae5e7d",
   "metadata": {},
   "source": [
    "### 4 - Fetch data via Rest API and pre process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e0955-261c-4cc9-b3e7-de2bc24ba83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from requests import get\n",
    "# Your actual API key\n",
    "api_key = os.environ.get(\"MY_API_KEY\")\n",
    "\n",
    "# Encode the API key using base64 for Basic Auth\n",
    "auth_string = f\"{api_key}:\"\n",
    "auth_bytes = auth_string.encode(\"utf-8\")\n",
    "auth_base64 = base64.b64encode(auth_bytes).decode(\"utf-8\")\n",
    "\n",
    "# Set Authorization header manually\n",
    "headers = {\n",
    "    \"Authorization\": f\"Basic {auth_base64}\",\n",
    "    \"Accept\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78db1df-67e6-41fd-853a-c4734f9e48c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "# Assume df contains a column 'CompanyNumber'\n",
    "company_numbers = df_unique['CompanyNumber'].dropna().unique()\n",
    "\n",
    "api_results = []\n",
    "\n",
    "# Loop through each CompanyNumber\n",
    "for number in company_numbers:\n",
    "    try:\n",
    "        url = f\"http://data.companieshouse.gov.uk/doc/company/{number}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            json_data = response.json()\n",
    "\n",
    "            if 'primaryTopic' in json_data:\n",
    "                api_results.append(json_data)\n",
    "                print(f\"Fetched data for CompanyNumber: {number}\")\n",
    "            else:\n",
    "                print(f\"No 'primaryTopic' found in response for {number}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Failed to fetch {number} â€” Status Code: {response.status_code}\")\n",
    "\n",
    "        time.sleep(0.2)  # be nice to the server\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {number}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225601eb-8a81-492f-81bb-905ce45453a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten into list of rows\n",
    "rows = []\n",
    "for item in api_results:\n",
    "    p = item['primaryTopic']\n",
    "    row = {\n",
    "        'CompanyName': p.get('CompanyName'),\n",
    "        'CompanyNumber': p.get('CompanyNumber'),\n",
    "        'AddressLine1': p.get('RegAddress', {}).get('AddressLine1'),\n",
    "        'PostTown': p.get('RegAddress', {}).get('PostTown'),\n",
    "        'Country': p.get('RegAddress', {}).get('Country'),\n",
    "        'Postcode': p.get('RegAddress', {}).get('Postcode'),\n",
    "        'CompanyCategory': p.get('CompanyCategory'),\n",
    "        'CompanyStatus': p.get('CompanyStatus'),\n",
    "        'CountryOfOrigin': p.get('CountryOfOrigin'),\n",
    "        'IncorporationDate': p.get('IncorporationDate'),\n",
    "        'AccountRefDay': p.get('Accounts', {}).get('AccountRefDay'),\n",
    "        'AccountRefMonth': p.get('Accounts', {}).get('AccountRefMonth'),\n",
    "        'NextAccountsDueDate': p.get('Accounts', {}).get('NextDueDate'),\n",
    "        'LastAccountsMadeUpDate': p.get('Accounts', {}).get('LastMadeUpDate'),\n",
    "        'ReturnsNextDueDate': p.get('Returns', {}).get('NextDueDate'),\n",
    "        'ReturnsLastMadeUpDate': p.get('Returns', {}).get('LastMadeUpDate'),\n",
    "        'SICCodes': \", \".join(p.get('SICCodes', {}).get('SicText', []))\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "df_api = pd.DataFrame(rows)\n",
    "\n",
    "# 2. Strip whitespace from column names (optional but helpful)\n",
    "df_api.columns = df_api.columns.str.strip()\n",
    "\n",
    "# 3. Trim whitespace in all string/object columns\n",
    "str_cols = df_api.select_dtypes(include=['object']).columns\n",
    "df_api[str_cols] = df_api[str_cols].apply(lambda x: x.str.strip())\n",
    "\n",
    "# List of columns to convert \n",
    "date_columns = [\n",
    "    'IncorporationDate',\n",
    "    'NextAccountsDueDate',\n",
    "    'LastAccountsMadeUpDate',\n",
    "    'ReturnsNextDueDate',\n",
    "    'ReturnsLastMadeUpDate'\n",
    "]\n",
    "\n",
    "# Apply conversion safely with error handling\n",
    "for col in date_columns:\n",
    "    if col in df_api.columns:\n",
    "        df_api[col] = pd.to_datetime(df_api[col], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "cols_to_int = [\n",
    "    'AccountRefDay',\n",
    "    'AccountRefMonth',\n",
    "   ]\n",
    "for col in cols_to_int:\n",
    "    if col in df_api.columns:\n",
    "        df_api[col] = pd.to_numeric(df_api[col], errors='coerce').astype('Int64')\n",
    "\n",
    "\n",
    "suffix = '_api'\n",
    "\n",
    "df_api = df_api.rename(columns={\n",
    "    col: col + suffix for col in df_api.columns if col != 'CompanyNumber'\n",
    "})\n",
    "# Show\n",
    "# df_api.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112943d2-e13d-4353-aaaa-54321a374fa3",
   "metadata": {},
   "source": [
    "### 5 - Merge both dfs to perform Matching and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ef2e6-9640-496b-a8bb-9f811beb4b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original=df_unique\n",
    "# Ensure CompanyNumber is string and used as merge key\n",
    "df_original['CompanyNumber'] = df_original['CompanyNumber'].astype(str).str.strip()\n",
    "df_api['CompanyNumber'] = df_api['CompanyNumber'].astype(str).str.strip()\n",
    "\n",
    "# Merge original and API data on CompanyNumber\n",
    "merged_df = pd.merge(\n",
    "    df_original, df_api,\n",
    "    on='CompanyNumber',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf380a2-0eaf-4015-b46d-2f2de31604ad",
   "metadata": {},
   "source": [
    "### 6 - Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac979d7d-e6c4-4652-a8cd-2a3402454da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your mappings\n",
    "column_map = {\n",
    "    'CompanyName': 'CompanyName_api',\n",
    "    'RegAddress.AddressLine1': 'AddressLine1_api',\n",
    "    'RegAddress.PostTown': 'PostTown_api',\n",
    "    'RegAddress.Country': 'Country_api',\n",
    "    'RegAddress.PostCode': 'Postcode_api',\n",
    "    'CompanyCategory': 'CompanyCategory_api',\n",
    "    'CompanyStatus': 'CompanyStatus_api',\n",
    "    'CountryOfOrigin': 'CountryOfOrigin_api',\n",
    "    'IncorporationDate': 'IncorporationDate_api',\n",
    "    'Accounts.AccountRefDay': 'AccountRefDay_api',\n",
    "    'Accounts.AccountRefMonth': 'AccountRefMonth_api',\n",
    "    'Accounts.NextDueDate': 'NextAccountsDueDate_api',\n",
    "    'Accounts.LastMadeUpDate': 'LastAccountsMadeUpDate_api',\n",
    "    'ReturnsNextDueDate': 'ReturnsNextDueDate_api',\n",
    "    'ReturnsLastMadeUpDate': 'ReturnsLastMadeUpDate_api'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b48a5-9bbe-489b-a96c-58407e885e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_df = merged_df.copy()\n",
    "\n",
    "for orig_col, api_col in column_map.items():\n",
    "    qa_col = orig_col.split('.')[-1] + '_QA'  # cleaner QA column name\n",
    "\n",
    "    def compare_values(row, orig=orig_col, api=api_col):\n",
    "        val1 = row.get(orig)\n",
    "        val2 = row.get(api)\n",
    "        try:\n",
    "            # 1. Return \"Missing in both sources\"\n",
    "            if pd.isna(val1) and pd.isna(val2):\n",
    "                return 'Missing in both sources'\n",
    "\n",
    "            # 2. Missing in original only\n",
    "            if pd.isna(val1) and pd.notna(val2):\n",
    "                return 'Missing in original source'\n",
    "\n",
    "            # 3. Missing in API only\n",
    "            if pd.isna(val2) and pd.notna(val1):\n",
    "                return 'Missing in api source'\n",
    "\n",
    "            # 4. Exact match\n",
    "            if val1 == val2:\n",
    "                return \"Matched\"\n",
    "\n",
    "            # 5. Mismatch\n",
    "            return \"Not Matched\"\n",
    "        except Exception as e:\n",
    "            return \"Error\"\n",
    "\n",
    "    validated_df[qa_col] = validated_df.apply(compare_values, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed1e79e-fdd1-4f25-8029-00644af2e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show QA columns\n",
    "qa_columns = [col for col in validated_df.columns if col.endswith('_QA')]\n",
    "validated_df[qa_columns].sample(6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20272f55-a4f6-4005-a21c-2558ac8090b0",
   "metadata": {},
   "source": [
    "### 7 - Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da03c64-5f14-41de-9d47-277607a33159",
   "metadata": {},
   "outputs": [],
   "source": [
    "for orig_col, api_col in column_map.items():\n",
    "    orig_full = f\"{orig_col}_original\"\n",
    "    api_full = f\"{api_col}_api\"\n",
    "    qa_col = orig_col.split('.')[-1] + '_QA'\n",
    "\n",
    "    # Only update if QA failed (i.e., 'No')\n",
    "    validated_df[orig_col] = validated_df.apply(\n",
    "        lambda row: row[api_col] if row.get(qa_col) in [\"Not Matched\",\"Missing in original source\"] and pd.notna(row[api_col]) else row[orig_col],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# Drop columns that end with _api or _QA\n",
    "enriched_df = validated_df.drop(columns=[\n",
    "    col for col in validated_df.columns if col.endswith('_api') or col.endswith('_QA')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a683c9-649f-47ce-bdb8-b33fd11380c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### incorporation age \n",
    "enriched_df['IncorporationDate'] = pd.to_datetime(enriched_df['IncorporationDate'], errors='coerce')\n",
    "enriched_df['CompanyAgeYears'] = ((pd.Timestamp.today() - enriched_df['IncorporationDate']).dt.days // 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d02689-09aa-4cbd-9620-5baea1182a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag whether accounts or returns are overdue using NextDueDate\n",
    "today = pd.Timestamp.today()\n",
    "enriched_df['AccountsOverdue'] = pd.to_datetime(enriched_df['Accounts.NextDueDate'], errors='coerce') < today\n",
    "enriched_df['ReturnsOverdue'] = pd.to_datetime(enriched_df['ReturnsNextDueDate'], errors='coerce') < today\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df21b87-5443-46ed-8846-fd3a04348c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add full address\n",
    "enriched_df['FullAddress'] = enriched_df['RegAddress.AddressLine1'].fillna('') + \", \" + \\\n",
    "                    enriched_df['RegAddress.PostTown'].fillna('') + \", \" + \\\n",
    "                    enriched_df['RegAddress.PostCode'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d40a18-fe41-4467-9736-ff62b9b52065",
   "metadata": {},
   "source": [
    "### 8 - Reporting and visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7218e0d9-c4d0-4743-984b-e5c34f5be3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how many records passed vs. failed for each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b741fcc-236b-406c-aa56-c4baabab787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "qa_columns = [col for col in validated_df.columns if col.endswith('_QA')]\n",
    "\n",
    "qa_summary = validated_df[qa_columns].apply(lambda col: col.value_counts().get('Not Matched', 0))\n",
    "qa_summary.plot(kind='barh', color='salmon', figsize=(8, 6), title='Mismatches per Field')\n",
    "\n",
    "plt.xlabel(\"Count of Mismatches\")\n",
    "plt.ylabel(\"Field\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa64428f-e62a-43e7-9cda-e86016753426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of companies with overdue filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f53ae5-f31c-4711-8356-67cec411b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_df['AccountsOverdue'] = pd.to_datetime(enriched_df['Accounts.NextDueDate'], errors='coerce') < pd.Timestamp.today()\n",
    "enriched_df['ReturnsOverdue'] = pd.to_datetime(enriched_df['ReturnsNextDueDate'], errors='coerce') < pd.Timestamp.today()\n",
    "\n",
    "overdue_counts = enriched_df[['AccountsOverdue', 'ReturnsOverdue']].sum()\n",
    "overdue_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a4823-00c6-4966-9f3b-1c7c506a9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot counts by country, postcode prefix, or city.\n",
    "enriched_df['RegAddress.PostTown'].value_counts().head(10).plot(kind='barh', color='steelblue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8609be1-3c0d-4e73-97e1-1fd0b1234574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be08b60-840e-4794-a211-23fe770cbd89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
