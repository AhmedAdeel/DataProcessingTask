{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34ea7fc6-1269-450d-a0bf-1c5cf343d90d",
   "metadata": {},
   "source": [
    "## DATA PROCESSING TASK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4143682f-c655-4eec-88e7-149c8aaebf29",
   "metadata": {},
   "source": [
    "##### This notebook presents a data engineering solution to profile, cleanse, deduplicate, and validate UK company data using the Companies House REST API. Starting from a raw CSV file (Company.csv), we standardize and enrich company records, ensuring data quality and accuracy. The final output includes a cleaned dataset, enrichment fields, and visual insights into data quality and API match success. Following steps are incuded: \n",
    "##### 1 - Import Libraries and Load Dataset\n",
    "##### 2 - Profiling\n",
    "##### 3 - Cleansing\n",
    "##### 4 - Deduplication\n",
    "##### 5 - API Data Fetch\n",
    "##### 6 - Data Merge\n",
    "##### 7 - Data Matching and Validation\n",
    "##### 8 - Enrichment\n",
    "##### 9 - Reporting and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c68bfc-6e35-4bfb-b83f-fb14b762e59e",
   "metadata": {},
   "source": [
    "### 1 - Import Libraries and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3cbeec-16f0-4e6a-a6ab-f23a0937e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sweetviz as sv\n",
    "import regex\n",
    "\n",
    "# 2. Load Dataset\n",
    "df = pd.read_csv(\"Company.csv\")\n",
    "# 3. Basic Structure\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a996cb-9b59-4f80-8c58-c649622cd9f9",
   "metadata": {},
   "source": [
    "### 2 - Data Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d5aec-ae99-4ebe-b173-0f2492f8f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Preview Data\n",
    "report = sv.analyze(df)\n",
    "report.show_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3555a90a-ee8e-430a-abcd-7ab12c374719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5. Summary Statistics (Including Strings)\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fae9c1b-73e5-4916-8ef4-2f4d3f509f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Missing Values\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "print(\"Columns with Missing Values:\\n\", missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03922617-b51a-4c8f-bea5-511a8fa77bc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 9. Top Company Names (possible duplicates)\n",
    "print(\"Top Repeated Company Numbers:\\n\", df[\" CompanyNumber\"].value_counts().head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf42a59-cbca-400a-91df-3a95fd12f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Top Company Number (possible duplicates)\n",
    "print(\"Top Repeated Company Names:\\n\", df[\"CompanyName\"].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190ce337-a1db-484d-8011-a5b0b5e64680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Unique Value Counts Per Column \n",
    "unique_counts = df.nunique().sort_values(ascending=False)\n",
    "print(\"Unique Values per Column:\\n\", unique_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9134a30-bf0b-43a6-8fb2-c13573b70d43",
   "metadata": {},
   "source": [
    "### 3 - Data Cleansing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f79351-40e4-4794-88ed-3ead391b3bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Drop columns where more than 90% values are NaN\n",
    "threshold = 276  # 90%\n",
    "null_count = df.isnull().sum()\n",
    "cols_to_drop = null_count[null_count > threshold].index\n",
    "print(f\"\\nDropping columns with more than {90}% missing values: {list(cols_to_drop)}\\n\")\n",
    "df.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb8bb1a-7081-442a-a20a-5570089e80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Strip whitespace from column names \n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# 3. Trim whitespace in all string/object columns\n",
    "str_cols = df.select_dtypes(include=['object']).columns\n",
    "df[str_cols] = df[str_cols].apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3289eca5-6098-40b1-8d2d-0c53a059d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer columns\n",
    "cols_to_int = [\n",
    "    'Accounts.AccountRefDay',\n",
    "    'Accounts.AccountRefMonth',\n",
    "    'Mortgages.NumMortCharges',\n",
    "    'Mortgages.NumMortOutstanding',\n",
    "    'Mortgages.NumMortPartSatisfied',\n",
    "    'Mortgages.NumMortSatisfied',\n",
    "    'LimitedPartnerships.NumGenPartners',\n",
    "    'LimitedPartnerships.NumLimPartners'\n",
    "]\n",
    "for col in cols_to_int:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')\n",
    "\n",
    "# Date columns\n",
    "# 5. Convert common date fields to datetime (ignore errors)\n",
    "date_columns = [col for col in df.columns if 'Date' in col]\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "## str columns\n",
    "str_cols = ['CompanyName', 'CompanyNumber', 'RegAddress.AddressLine1',\n",
    "       'RegAddress.AddressLine2', 'RegAddress.PostTown',\n",
    "       'RegAddress.County', 'RegAddress.Country', 'RegAddress.PostCode',\n",
    "       'CompanyCategory', 'CompanyStatus', 'CountryOfOrigin',\n",
    "        'Accounts.AccountCategory','SICCode.SicText_1', 'SICCode.SicText_2']\n",
    "for col in str_cols:\n",
    "    df[col] = df[col].str.upper().str.strip().str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe77f2a-f0bd-4f05-bfda-648a35823977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "df = df.rename(columns={\n",
    "    'Returns.NextDueDate': 'ReturnsNextDueDate',\n",
    "    'Returns.LastMadeUpDate': 'ReturnsLastMadeUpDate'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09fcfbf-a8da-438d-930a-0c27759666c5",
   "metadata": {},
   "source": [
    "#### a - Cleaning key columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61337c8b-5abc-4277-8bcb-be38f3fadd92",
   "metadata": {},
   "source": [
    "##### - RegAddress.Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e53f0a-e602-4c73-a35c-5d50f22ea1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RegAddress.Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976f5b97-efda-41b0-8dcb-db3bef46771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mapping rules\n",
    "country_cleaning_map = {\n",
    "    'ENGLAND': 'UNITED KINGDOM',\n",
    "    'UK': 'UNITED KINGDOM',\n",
    "    'SCOTLAND': 'UNITED KINGDOM',\n",
    "    'WALES': 'UNITED KINGDOM',\n",
    "    'NORTHERN IRELAND': 'UNITED KINGDOM',\n",
    "    '05/02/1980': '',  # Invalid entry\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "df['RegAddress.Country'] = df['RegAddress.Country'].replace(country_cleaning_map)\n",
    "\n",
    "df['RegAddress.Country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9741d31-550b-4b66-897a-01e089d7a619",
   "metadata": {},
   "source": [
    "##### - CompanyCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d4e285-aa52-44e4-b8cd-c3f9d4731bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CompanyCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b46b8e-f931-45ad-a1d1-c3a26a1e537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardization mapping\n",
    "category_map = {\n",
    "    'PRIVATE LIMITED COMPANY': 'Private Limited Company',\n",
    "    'PRIVATE LTD COMPANY': 'Private Limited Company',\n",
    "    'PRI/LTD BY GUAR/NSC (PRIVATE, LIMITED BY GUARANTEE, NO SHARE CAPITAL)': 'Private Ltd by Guarantee (No Share Capital)',\n",
    "    'PRI/LTD BY GUAR/NSC (PRIVATE, LTD BY GUARANTEE, NO SHARE CAPITAL)': 'Private Ltd by Guarantee (No Share Capital)',\n",
    "    'PRI/LBG/NSC (PRIVATE, LIMITED BY GUARANTEE, NO SHARE CAPITAL, USE OF \\'LIMITED\\' EXEMPTION)': 'Ltd by Guarantee (Limited Exemption)',\n",
    "    'LIMITED LIABILITY PARTNERSHIP': 'Limited Liability Partnership',\n",
    "    'LIMITED PARTNERSHIP': 'Limited Partnership',\n",
    "    'OVERSEAS ENTITY': 'Overseas Entity',\n",
    "    'OTHER COMPANY TYPE': 'Other Company Type',\n",
    "    '5': '',  # Invalid entry\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "df['CompanyCategory'] = df['CompanyCategory'].replace(category_map)\n",
    "\n",
    "# Optional: Capitalize uniformly\n",
    "df['CompanyCategory'] = df['CompanyCategory'].str.title()\n",
    "\n",
    "df['CompanyCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efacaa20-080b-4a06-b338-b54ae7d59558",
   "metadata": {},
   "source": [
    "##### - CompanyStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57351923-d56d-4535-8bc3-430cda572f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CompanyStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b319e4c-e7e6-4bf5-8346-21680fcaafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning map\n",
    "status_map = {\n",
    "    'ACTIVE': 'Active',\n",
    "    'ACTIVE - PROPOSAL TO STRIKE OFF': 'Active (To Strike Off)',\n",
    "    'ACTIVE, UK\"': 'Active',\n",
    "    'LIQUIDATION': 'Liquidation',\n",
    "    'VOLUNTARY ARRANGEMENT': 'Voluntary Arrangement',\n",
    "    '31/03/1988': '',  # Invalid entry\n",
    "}\n",
    "\n",
    "# Apply map\n",
    "df['CompanyStatus'] = df['CompanyStatus'].replace(status_map)\n",
    "\n",
    "# Optional: Title case everything\n",
    "df['CompanyStatus'] = df['CompanyStatus'].str.title()\n",
    "df['CompanyStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca417ca1-812a-402f-b4d2-a9b9bc174c44",
   "metadata": {},
   "source": [
    "##### - CountryOfOrigin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06563d7b-4139-4cb2-b614-ce4bcc90f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CountryOfOrigin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0768c84f-c5af-4d06-95ee-78da83e7074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cleaning map\n",
    "origin_map = {\n",
    "    'UK': 'United Kingdom',\n",
    "    'UNITED KINGDOM': 'United Kingdom',\n",
    "    '31/05/1986': '',  # Invalid entry\n",
    "}\n",
    "\n",
    "# Apply map\n",
    "df['CountryOfOrigin'] = df['CountryOfOrigin'].replace(origin_map)\n",
    "\n",
    "# Optional: Title case for consistency\n",
    "df['CountryOfOrigin'] = df['CountryOfOrigin'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4ebef0-6466-4e50-b16a-bb6ef7a3dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CountryOfOrigin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b22750d-3778-46c2-8aed-1ce4eb0a93f1",
   "metadata": {},
   "source": [
    " ##### - Postal Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866ba1a-2d7d-4c64-947c-c7f1e8722291",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_postcode_regex = r\"^[A-Z]{1,2}\\d{1,2}[A-Z]?\\s?\\d[A-Z]{2}$\"\n",
    "df['ValidPostcode'] = df['RegAddress.PostCode'].str.upper().str.match(uk_postcode_regex)\n",
    "df['ValidPostcode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4808e58f-4cca-4125-9d8d-be8f4b2631a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_int = [\n",
    "    'Accounts.AccountRefDay',\n",
    "    'Accounts.AccountRefMonth',\n",
    "    'Mortgages.NumMortCharges',\n",
    "    'Mortgages.NumMortOutstanding',\n",
    "    'Mortgages.NumMortPartSatisfied',\n",
    "    'Mortgages.NumMortSatisfied',\n",
    "    'LimitedPartnerships.NumGenPartners',\n",
    "    'LimitedPartnerships.NumLimPartners'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a03af-e87d-45fc-98a5-27e724dc3d6b",
   "metadata": {},
   "source": [
    "##### - Accounts.AccountRefDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac29e6c4-f56e-45f6-a58f-4e09422920c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Accounts.AccountRefDay'].fillna(999).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d49ab9c-2fdf-4bfb-933f-602d513997c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Accounts.AccountRefDay'] = df['Accounts.AccountRefDay'].fillna(999)\n",
    "df['Accounts.AccountRefDay'] = df['Accounts.AccountRefDay'].apply(lambda x: 999 if x > 31 else x)\n",
    "df['Accounts.AccountRefDay'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9eb35f-2a31-4a2d-a1f1-c4e55f33cd83",
   "metadata": {},
   "source": [
    "##### - Accounts.AccountRefMonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354b02e7-5e62-464b-a32a-c4a9acfd8f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Accounts.AccountRefMonth'].fillna(999).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f1d0ca-7af3-48ca-b1fb-c859c18dc359",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Accounts.AccountRefMonth'] = df['Accounts.AccountRefMonth'].fillna(999)\n",
    "df['Accounts.AccountRefMonth'] = df['Accounts.AccountRefMonth'].apply(lambda x: x if 1 <= x <= 12 else 999)\n",
    "df['Accounts.AccountRefMonth'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc38bd0a-2877-4c17-bd86-3bc5def31ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Show result\n",
    "print(\"Cleansing completed. New shape:\", df.shape)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a3508f-728f-45db-a1ba-de9777298bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ea158-c33b-42c7-b5bd-627db24fb83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sweet = df.select_dtypes(exclude=['boolean', 'Int64'])\n",
    "report = sv.analyze(df_sweet)\n",
    "report.show_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88360f23-83f9-4b71-b5d5-3804d136e322",
   "metadata": {},
   "source": [
    "### 4 - Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7da82-d31c-4998-b5ca-e1b63e2afa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicated CompanyNumber entries (including all duplicates, not just the second+)\n",
    "duplicates = df[df.duplicated(subset='CompanyNumber', keep=False)]\n",
    "\n",
    "# Sort for readability\n",
    "duplicates = duplicates.sort_values(by='CompanyNumber')\n",
    "\n",
    "# Display duplicated rows\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e82b61-46f7-498a-8d8c-c5f23b0807db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Group by CompanyNumber and merge fields\n",
    "def merge_group(group):\n",
    "    # Take the first non-null value from each column\n",
    "    return group.ffill().bfill().iloc[0]\n",
    "\n",
    "# Only apply if CompanyNumber column exists\n",
    "if 'CompanyNumber' in df.columns:\n",
    "    # Create merged DataFrame by group\n",
    "    df_unique = df.groupby('CompanyNumber', as_index=False).apply(merge_group)\n",
    "\n",
    "    # Reset index after groupby\n",
    "    df_unique.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Deduplication done. Reduced from {df.shape[0]} to {df_unique.shape[0]} rows.\")\n",
    "else:\n",
    "    print(\"CompanyNumber column not found for deduplication.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83f8b0e-d5b7-48ba-9c95-20c820df33fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df_unique[df_unique['CompanyNumber'].notnull()]\n",
    "len(df_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c132ffe-a6d0-4d07-ad01-7d81f2ae5e7d",
   "metadata": {},
   "source": [
    "### 4 - Fetch data via Rest API and pre process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e0955-261c-4cc9-b3e7-de2bc24ba83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from requests import get\n",
    "# Your actual API key\n",
    "api_key = os.environ.get(\"MY_API_KEY\")\n",
    "\n",
    "# Encode the API key using base64 for Basic Auth\n",
    "auth_string = f\"{api_key}:\"\n",
    "auth_bytes = auth_string.encode(\"utf-8\")\n",
    "auth_base64 = base64.b64encode(auth_bytes).decode(\"utf-8\")\n",
    "\n",
    "# Set Authorization header manually\n",
    "headers = {\n",
    "    \"Authorization\": f\"Basic {auth_base64}\",\n",
    "    \"Accept\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78db1df-67e6-41fd-853a-c4734f9e48c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "# Assume df contains a column 'CompanyNumber'\n",
    "company_numbers = df_unique['CompanyNumber'].dropna().unique()\n",
    "\n",
    "api_results = []\n",
    "\n",
    "# Loop through each CompanyNumber\n",
    "for number in company_numbers:\n",
    "    try:\n",
    "        url = f\"http://data.companieshouse.gov.uk/doc/company/{number}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            json_data = response.json()\n",
    "\n",
    "            if 'primaryTopic' in json_data:\n",
    "                api_results.append(json_data)\n",
    "                print(f\"Fetched data for CompanyNumber: {number}\")\n",
    "            else:\n",
    "                print(f\"No 'primaryTopic' found in response for {number}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Failed to fetch {number} â€” Status Code: {response.status_code}\")\n",
    "\n",
    "        time.sleep(0.2)  # be nice to the server\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {number}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225601eb-8a81-492f-81bb-905ce45453a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten into list of rows\n",
    "rows = []\n",
    "for item in api_results:\n",
    "    p = item['primaryTopic']\n",
    "    row = {\n",
    "        'CompanyName': p.get('CompanyName'),\n",
    "        'CompanyNumber': p.get('CompanyNumber'),\n",
    "        'AddressLine1': p.get('RegAddress', {}).get('AddressLine1'),\n",
    "        'PostTown': p.get('RegAddress', {}).get('PostTown'),\n",
    "        'Country': p.get('RegAddress', {}).get('Country'),\n",
    "        'Postcode': p.get('RegAddress', {}).get('Postcode'),\n",
    "        'CompanyCategory': p.get('CompanyCategory'),\n",
    "        'CompanyStatus': p.get('CompanyStatus'),\n",
    "        'CountryOfOrigin': p.get('CountryOfOrigin'),\n",
    "        'IncorporationDate': p.get('IncorporationDate'),\n",
    "        'AccountRefDay': p.get('Accounts', {}).get('AccountRefDay'),\n",
    "        'AccountRefMonth': p.get('Accounts', {}).get('AccountRefMonth'),\n",
    "        'NextAccountsDueDate': p.get('Accounts', {}).get('NextDueDate'),\n",
    "        'LastAccountsMadeUpDate': p.get('Accounts', {}).get('LastMadeUpDate'),\n",
    "        'ReturnsNextDueDate': p.get('Returns', {}).get('NextDueDate'),\n",
    "        'ReturnsLastMadeUpDate': p.get('Returns', {}).get('LastMadeUpDate'),\n",
    "        'SICCodes': \", \".join(p.get('SICCodes', {}).get('SicText', []))\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "df_api = pd.DataFrame(rows)\n",
    "\n",
    "# 2. Strip whitespace from column names (optional but helpful)\n",
    "df_api.columns = df_api.columns.str.strip()\n",
    "\n",
    "# 3. Trim whitespace in all string/object columns\n",
    "str_cols = df_api.select_dtypes(include=['object']).columns\n",
    "df_api[str_cols] = df_api[str_cols].apply(lambda x: x.str.strip())\n",
    "\n",
    "# List of columns to convert \n",
    "date_columns = [\n",
    "    'IncorporationDate',\n",
    "    'NextAccountsDueDate',\n",
    "    'LastAccountsMadeUpDate',\n",
    "    'ReturnsNextDueDate',\n",
    "    'ReturnsLastMadeUpDate'\n",
    "]\n",
    "\n",
    "# Apply conversion safely with error handling\n",
    "for col in date_columns:\n",
    "    if col in df_api.columns:\n",
    "        df_api[col] = pd.to_datetime(df_api[col], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "cols_to_int = [\n",
    "    'AccountRefDay',\n",
    "    'AccountRefMonth',\n",
    "   ]\n",
    "for col in cols_to_int:\n",
    "    if col in df_api.columns:\n",
    "        df_api[col] = pd.to_numeric(df_api[col], errors='coerce').astype('Int64')\n",
    "\n",
    "\n",
    "suffix = '_api'\n",
    "\n",
    "df_api = df_api.rename(columns={\n",
    "    col: col + suffix for col in df_api.columns if col != 'CompanyNumber'\n",
    "})\n",
    "# Show\n",
    "# df_api.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd93d45-4ff2-4231-b2cd-da00cadcaa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112943d2-e13d-4353-aaaa-54321a374fa3",
   "metadata": {},
   "source": [
    "### 5 - Merge both dfs to perform Matching and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ef2e6-9640-496b-a8bb-9f811beb4b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original=df_unique\n",
    "# Ensure CompanyNumber is string and used as merge key\n",
    "df_original['CompanyNumber'] = df_original['CompanyNumber'].astype(str).str.strip()\n",
    "df_api['CompanyNumber'] = df_api['CompanyNumber'].astype(str).str.strip()\n",
    "\n",
    "# Merge original and API data on CompanyNumber\n",
    "merged_df = pd.merge(\n",
    "    df_original, df_api,\n",
    "    on='CompanyNumber',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf380a2-0eaf-4015-b46d-2f2de31604ad",
   "metadata": {},
   "source": [
    "### 6 - Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac979d7d-e6c4-4652-a8cd-2a3402454da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your mappings\n",
    "column_map = {\n",
    "    'CompanyName': 'CompanyName_api',\n",
    "    'RegAddress.AddressLine1': 'AddressLine1_api',\n",
    "    'RegAddress.PostTown': 'PostTown_api',\n",
    "    'RegAddress.Country': 'Country_api',\n",
    "    'RegAddress.PostCode': 'Postcode_api',\n",
    "    'CompanyCategory': 'CompanyCategory_api',\n",
    "    'CompanyStatus': 'CompanyStatus_api',\n",
    "    'CountryOfOrigin': 'CountryOfOrigin_api',\n",
    "    'IncorporationDate': 'IncorporationDate_api',\n",
    "    'Accounts.AccountRefDay': 'AccountRefDay_api',\n",
    "    'Accounts.AccountRefMonth': 'AccountRefMonth_api',\n",
    "    'Accounts.NextDueDate': 'NextAccountsDueDate_api',\n",
    "    'Accounts.LastMadeUpDate': 'LastAccountsMadeUpDate_api',\n",
    "    'ReturnsNextDueDate': 'ReturnsNextDueDate_api',\n",
    "    'ReturnsLastMadeUpDate': 'ReturnsLastMadeUpDate_api'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b48a5-9bbe-489b-a96c-58407e885e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_df = merged_df.copy()\n",
    "\n",
    "for orig_col, api_col in column_map.items():\n",
    "    qa_col = orig_col.split('.')[-1] + '_QA'  # cleaner QA column name\n",
    "\n",
    "    def compare_values(row, orig=orig_col, api=api_col):\n",
    "        val1 = row.get(orig)\n",
    "        val2 = row.get(api)\n",
    "        try:\n",
    "            # 1. Return \"Missing in both sources\"\n",
    "            if pd.isna(val1) and pd.isna(val2):\n",
    "                return 'Missing in both sources'\n",
    "\n",
    "            # 2. Missing in original only\n",
    "            if pd.isna(val1) and pd.notna(val2):\n",
    "                return 'Missing in original source'\n",
    "\n",
    "            # 3. Missing in API only\n",
    "            if pd.isna(val2) and pd.notna(val1):\n",
    "                return 'Missing in api source'\n",
    "\n",
    "            # 4. Exact match\n",
    "            if val1 == val2:\n",
    "                return \"Matched\"\n",
    "\n",
    "            # 5. Mismatch\n",
    "            return \"Not Matched\"\n",
    "        except Exception as e:\n",
    "            return \"Error\"\n",
    "\n",
    "    validated_df[qa_col] = validated_df.apply(compare_values, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed1e79e-fdd1-4f25-8029-00644af2e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show QA columns\n",
    "qa_columns = [col for col in validated_df.columns if col.endswith('_QA')]\n",
    "validated_df[qa_columns].sample(6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20272f55-a4f6-4005-a21c-2558ac8090b0",
   "metadata": {},
   "source": [
    "### 7 - Enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d281055-f854-4f78-920c-57d20ba1584e",
   "metadata": {},
   "source": [
    "##### - Update Missing and Mismatching values in original df with values from api results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da03c64-5f14-41de-9d47-277607a33159",
   "metadata": {},
   "outputs": [],
   "source": [
    "for orig_col, api_col in column_map.items():\n",
    "    orig_full = f\"{orig_col}_original\"\n",
    "    api_full = f\"{api_col}_api\"\n",
    "    qa_col = orig_col.split('.')[-1] + '_QA'\n",
    "\n",
    "    # Only update if QA failed (i.e., 'No')\n",
    "    validated_df[orig_col] = validated_df.apply(\n",
    "        lambda row: row[api_col] if row.get(qa_col) in [\"Not Matched\",\"Missing in original source\"] and pd.notna(row[api_col]) else row[orig_col],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# Drop columns that end with _api or _QA\n",
    "enriched_df = validated_df.drop(columns=[\n",
    "    col for col in validated_df.columns if col.endswith('_api') or col.endswith('_QA')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77f8a2d-e1f7-428f-bda3-8c6a8ee833ff",
   "metadata": {},
   "source": [
    "##### - Add Company Age Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a683c9-649f-47ce-bdb8-b33fd11380c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### incorporation age \n",
    "enriched_df['IncorporationDate'] = pd.to_datetime(enriched_df['IncorporationDate'], errors='coerce')\n",
    "enriched_df['CompanyAgeYears'] = ((pd.Timestamp.today() - enriched_df['IncorporationDate']).dt.days // 365)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede1ca60-29fc-4532-bb29-655b00ea2c47",
   "metadata": {},
   "source": [
    "##### - Flag Overdue Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d02689-09aa-4cbd-9620-5baea1182a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag whether accounts or returns are overdue using NextDueDate\n",
    "today = pd.Timestamp.today()\n",
    "enriched_df['AccountsOverdue'] = pd.to_datetime(enriched_df['Accounts.NextDueDate'], errors='coerce') < today\n",
    "enriched_df['ReturnsOverdue'] = pd.to_datetime(enriched_df['ReturnsNextDueDate'], errors='coerce') < today\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b41ca7-db63-4039-a0d0-fea1679bd9e6",
   "metadata": {},
   "source": [
    "##### - Add full Address column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df21b87-5443-46ed-8846-fd3a04348c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add full address\n",
    "enriched_df['FullAddress'] = enriched_df['RegAddress.AddressLine1'].fillna('') + \", \" + \\\n",
    "                    enriched_df['RegAddress.AddressLine2'].fillna('') + \", \" + \\\n",
    "                    enriched_df['RegAddress.PostTown'].fillna('') + \", \" + \\\n",
    "                    enriched_df['RegAddress.PostCode'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143ac4d5-babc-4fe5-a82b-2629d911ad3c",
   "metadata": {},
   "source": [
    "##### - Extract Code and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da49844-d53a-4304-ab9e-a88097633b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract code and text from 'SICCode.SicText_1'\n",
    "df[['SICCode_1', 'SICText_1']] = df['SICCode.SicText_1'].str.extract(r'^(\\d{4,})\\s*-\\s*(.+)$')\n",
    "df[['SICCode_2', 'SICText_2']] = df['SICCode.SicText_2'].str.extract(r'^(\\d{4,})\\s*-\\s*(.+)$')\n",
    "\n",
    "# Optional: Handle 'NONE SUPPLIED' and other non-standard entries\n",
    "df['SICCode_1'] = df['SICCode_1'].fillna('None Supplied')\n",
    "df['SICText_1'] = df['SICText_1'].fillna('None Supplied')\n",
    "df['SICCode_2'] = df['SICCode_2'].fillna('None Supplied')\n",
    "df['SICText_2'] = df['SICText_2'].fillna('None Supplied')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d40a18-fe41-4467-9736-ff62b9b52065",
   "metadata": {},
   "source": [
    "### 8 - Reporting and visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7218e0d9-c4d0-4743-984b-e5c34f5be3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how many records passed vs. failed for each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b741fcc-236b-406c-aa56-c4baabab787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "qa_columns = [col for col in validated_df.columns if col.endswith('_QA')]\n",
    "\n",
    "qa_summary = validated_df[qa_columns].apply(lambda col: col.value_counts().get('Not Matched', 0))\n",
    "qa_summary.plot(kind='barh', color='salmon', figsize=(8, 6), title='Mismatches per Field')\n",
    "\n",
    "plt.xlabel(\"Count of Mismatches\")\n",
    "plt.ylabel(\"Field\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa64428f-e62a-43e7-9cda-e86016753426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of companies with overdue filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f53ae5-f31c-4711-8356-67cec411b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_df['AccountsOverdue'] = pd.to_datetime(enriched_df['Accounts.NextDueDate'], errors='coerce') < pd.Timestamp.today()\n",
    "enriched_df['ReturnsOverdue'] = pd.to_datetime(enriched_df['ReturnsNextDueDate'], errors='coerce') < pd.Timestamp.today()\n",
    "\n",
    "overdue_counts = enriched_df[['AccountsOverdue', 'ReturnsOverdue']].sum()\n",
    "overdue_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a4823-00c6-4966-9f3b-1c7c506a9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot counts by PostTown.\n",
    "enriched_df['RegAddress.PostTown'].value_counts().head(10).plot(kind='barh', color='steelblue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8609be1-3c0d-4e73-97e1-1fd0b1234574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot counts by PostTown.\n",
    "enriched_df['CompanyStatus'].value_counts().head(10).plot(kind='barh', color='steelblue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be08b60-840e-4794-a211-23fe770cbd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot counts by PostTown.\n",
    "enriched_df['CompanyAgeYears'].value_counts().head(10).plot(kind='barh', color='steelblue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a655d-c28a-4a99-b21a-ec4a68ce86d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
